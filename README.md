 <b><h1><p  align="center"> NLP-Sentence-Similarity </p></h1></b>

<ol>
<li><a href="https://arxiv.org/pdf/1803.05449v1.pdf">SentEval: An Evaluation Toolkit for Universal Sentence Representations</a></li>
<li><a href="https://arxiv.org/pdf/1802.05667v2.pdf">Calculating the similarity between words and sentences using a lexical database and corpus statistics</a></li>
<li><a href="https://arxiv.org/pdf/2004.03844v3.pdf">On the Effect of Dropping Layers of Pre-trained Transformer Models</a></li>
<li><a href="https://arxiv.org/pdf/1709.08878v2.pdf">Generating Sentences by Editing Prototypes</a></li>
<li><a href="https://arxiv.org/pdf/1611.02654v2.pdf">Sentence Ordering and Coherence Modeling using Recurrent Neural Networks</a></li>
<li><a href="https://arxiv.org/pdf/1707.07806v2.pdf">Macro Grammars and Holistic Triggering for Efficient Semantic Parsing</a></li>
<li><a href="https://arxiv.org/pdf/1808.09663v6.pdf">Context Mover's Distance & Barycenters: Optimal Transport of Contexts for Building Representations</a></li>
<li><a href="https://arxiv.org/pdf/1812.08306v1.pdf">NeuralWarp: Time-Series Similarity with Warping Networks</a></li>
<li><a href="https://arxiv.org/pdf/1602.07019v2.pdf">Sentence Similarity Learning by Lexical Decomposition and Composition</a></li>
<li><a href="https://arxiv.org/pdf/1603.06807v2.pdf">Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus</a></li>
<li><a href="https://arxiv.org/pdf/1605.01194v1.pdf">IISCNLP at SemEval-2016 Task 2: Interpretable STS with ILP based Multiple Chunk Aligner</a></li>
<li><a href="https://arxiv.org/pdf/1610.03098v3.pdf">Neural Paraphrase Generation with Stacked Residual LSTM Networks</a></li>
<li><a href="https://arxiv.org/pdf/1709.01186v1.pdf">Learning Neural Word Salience Scores</a></li>
<li><a href="https://arxiv.org/pdf/1807.00717v1.pdf">Transparent, Efficient, and Robust Word Embedding Access with WOMBAT</a></li>
<li><a href="https://arxiv.org/pdf/1808.10025v1.pdf">Retrieval-Based Neural Code Generation</a></li>
<li><a href="https://aclanthology.org/D18-1328.pdf">Fixing Translation Divergences in Parallel Corpora for Neural MT</a></li>
<li><a href="https://aclanthology.org/N19-1023.pdf">Evaluating Composition Models for Verb Phrase Elliptical Sentence Embeddings</a></li>
<li><a href="https://arxiv.org/pdf/2004.06190v3.pdf">A Divide-and-Conquer Approach to the Summarization of Long Documents</a></li>
<li><a href="https://aclanthology.org/2020.lrec-1.676.pdf">Contextualized Embeddings based Transformer Encoder for Sentence Similarity Modeling in Answer Selection Task</a></li>
<li><a href="https://arxiv.org/pdf/2005.08367v1.pdf">DEXA: Supporting Non-Expert Annotators with Dynamic Examples from Experts</a></li>
<li><a href="https://arxiv.org/pdf/2006.04666v2.pdf">Misinformation Has High Perplexity</a></li>
<li><a href="https://aclanthology.org/2020.acl-main.152.pdf">Parallel Sentence Mining by Constrained Decoding</a></li>
<li><a href="https://arxiv.org/pdf/2010.08269v1.pdf">Effective Distributed Representations for Academic Expert Search</a></li>
<li><a href="https://arxiv.org/pdf/2010.08684v2.pdf">Example-Driven Intent Prediction with Observers</a></li>
<li><a href="https://aclanthology.org/2020.conll-1.24.pdf">Representation Learning for Type-Driven Composition</a></li>
<li><a href="https://arxiv.org/pdf/2011.01421v1.pdf">WSL-DS: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization</a></li>
<li><a href="https://arxiv.org/pdf/2012.14700v1.pdf">Image-to-Image Retrieval by Learning Similarity between Scene Graphs</a></li>
<li><a href="https://arxiv.org/pdf/2101.06423v2.pdf">Match-Ignition: Plugging PageRank into Transformer for Long-form Text Matching</a></li>
<li><a href="https://arxiv.org/pdf/2104.08027v2.pdf">Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders</a></li>
<li><a href="https://arxiv.org/ftp/arxiv/papers/2105/2105.00648.pdf">A novel hybrid methodology of measuring sentence similarity</a></li>
<li><a href="https://aclanthology.org/2021.bionlp-1.16.pdf">BioELECTRA:Pretrained Biomedical text Encoder using Discriminators</a></li>
<li><a href="https://arxiv.org/pdf/2106.08648v1.pdf">Semantic sentence similarity: size does not always matter</a></li>
<li><a href="https://arxiv.org/pdf/2106.10955v1.pdf">Extractive approach for text summarisation using graphs</a></li>
<li><a href="https://arxiv.org/pdf/2107.04374v1.pdf">Benchmarking for Biomedical Natural Language Processing Tasks with a Domain Specific ALBERT</a></li>
<li><a href="https://arxiv.org/pdf/2107.05132v2.pdf">LexSubCon: Integrating Knowledge from Lexical Resources into Contextual Embeddings for Lexical Substitution</a></li>
<li><a href="https://arxiv.org/pdf/2109.08449v2.pdf">General Cross-Architecture Distillation of Pretrained Language Models into Matrix Embeddings</a></li>
<li><a href="https://arxiv.org/pdf/2109.10509v1.pdf">Unsupervised Contextualized Document Representation</a></li>
</ol>
